{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z0oj4HS26x05",
        "outputId": "d42542f5-9c53-4c3d-f81d-a5242f1c1865",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-gbq 0.19.2 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n",
            "tensorflow-datasets 4.9.4 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q \"tensorflow-text==2.11.*\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "alf2kDHJ60rO"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "k4a11Hlm7C4k",
        "outputId": "5494a40f-e591-4525-e76c-9f98042d9252",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[b'What', b'you', b'know', b'you', b\"can't\", b'explain,', b'but', b'you', b'feel', b'it.']]\n"
          ]
        }
      ],
      "source": [
        "tokenizer = tf_text.WhitespaceTokenizer()\n",
        "tokens = tokenizer.tokenize([\"What you know you can't explain, but you feel it.\"])\n",
        "print(tokens.to_list())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "68u0XF3L6-ay",
        "outputId": "383f1bd9-b1a2-45da-fcd2-e64ef5ecc334",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[b'What', b'you', b'know', b'you', b'can', b\"'\", b't', b'explain', b',', b'but', b'you', b'feel', b'it', b'.']]\n"
          ]
        }
      ],
      "source": [
        "tokenizer = tf_text.UnicodeScriptTokenizer()\n",
        "tokens = tokenizer.tokenize([\"What you know you can't explain, but you feel it.\"])\n",
        "print(tokens.to_list())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "srIHtzU2fxCi",
        "outputId": "d4f1c93f-cafe-4463-8c4d-7dfaac5cd923",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[b'What', b'you', b'know', b'you', b\"can't\", b'explain,', b'but', b'you', b'feel', b'it.']]\n"
          ]
        }
      ],
      "source": [
        "tokenizer = tf_text.WhitespaceTokenizer()\n",
        "tokens = tokenizer.tokenize([\"What you know you can't explain, but you feel it.\"])\n",
        "print(tokens.to_list())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ISEUjIsYAl2S",
        "outputId": "822197d6-b2e9-4ef5-c9fc-2ca798df7b48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52382"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "url = \"https://github.com/tensorflow/text/blob/master/tensorflow_text/python/ops/test_data/test_wp_en_vocab.txt?raw=true\"\n",
        "r = requests.get(url)\n",
        "filepath = \"vocab.txt\"\n",
        "open(filepath, 'wb').write(r.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uU8wJlUfsskU",
        "outputId": "1aa185e5-c12a-48ff-a9ce-4f209c815903",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[b'What'], [b'you'], [b'know'], [b'you'], [b\"can't\"], [b'explain,'], [b'but'], [b'you'], [b'feel'], [b'it.']]]\n"
          ]
        }
      ],
      "source": [
        "subtokenizer = tf_text.UnicodeScriptTokenizer(filepath)\n",
        "subtokens = tokenizer.tokenize(tokens)\n",
        "print(subtokens.to_list())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2tOz1hNhtdV2",
        "outputId": "0256c5d2-8e4d-4ea4-c380-3e8210ce8fdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[b'what'], [b'you'], [b'know'], [b'you'], [b'can'], [b\"'\"], [b't'], [b'explain'], [b','], [b'but'], [b'you'], [b'feel'], [b'it'], [b'.']]]\n"
          ]
        }
      ],
      "source": [
        "tokenizer = tf_text.BertTokenizer(filepath, token_out_type=tf.string, lower_case=True)\n",
        "tokens = tokenizer.tokenize([\"What you know you can't explain, but you feel it.\"])\n",
        "print(tokens.to_list())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0dUbFCfDCojr"
      },
      "outputs": [],
      "source": [
        "url = \"https://github.com/tensorflow/text/blob/master/tensorflow_text/python/ops/test_data/test_oss_model.model?raw=true\"\n",
        "sp_model = requests.get(url).content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uvsm6iuNupEZ",
        "outputId": "8d8a9d75-3bdd-4e6d-f9f2-8743070b345e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[b'\\xe2\\x96\\x81What', b'\\xe2\\x96\\x81you', b'\\xe2\\x96\\x81know', b'\\xe2\\x96\\x81you', b'\\xe2\\x96\\x81can', b\"'\", b't', b'\\xe2\\x96\\x81explain', b',', b'\\xe2\\x96\\x81but', b'\\xe2\\x96\\x81you', b'\\xe2\\x96\\x81feel', b'\\xe2\\x96\\x81it', b'.']]\n"
          ]
        }
      ],
      "source": [
        "tokenizer = tf_text.SentencepieceTokenizer(sp_model, out_type=tf.string)\n",
        "tokens = tokenizer.tokenize([\"What you know you can't explain, but you feel it.\"])\n",
        "print(tokens.to_list())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4GjiAnQFvIhW",
        "outputId": "e31cb790-fe27-4b18-cf59-a0493eb78697",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[87, 104, 97, 116, 32, 121, 111, 117, 32, 107, 110, 111, 119, 32, 121, 111, 117, 32, 99, 97, 110, 39, 116, 32, 101, 120, 112, 108, 97, 105, 110, 44, 32, 98, 117, 116, 32, 121, 111, 117, 32, 102, 101, 101, 108, 32, 105, 116, 46]]\n"
          ]
        }
      ],
      "source": [
        "tokenizer = tf_text.UnicodeCharTokenizer()\n",
        "tokens = tokenizer.tokenize([\"What you know you can't explain, but you feel it.\"])\n",
        "print(tokens.to_list())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_uuyz3XC0NdU",
        "outputId": "17db1089-b4ab-41f8-8cb9-9268bbcaeb3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[b'Wh', b'ha', b'at', b't ', b' y', b'yo', b'ou', b'u ', b' k', b'kn', b'no', b'ow', b'w ', b' y', b'yo', b'ou', b'u ', b' c', b'ca', b'an', b\"n'\", b\"'t\", b't ', b' e', b'ex', b'xp', b'pl', b'la', b'ai', b'in', b'n,', b', ', b' b', b'bu', b'ut', b't ', b' y', b'yo', b'ou', b'u ', b' f', b'fe', b'ee', b'el', b'l ', b' i', b'it', b't.']]\n"
          ]
        }
      ],
      "source": [
        "characters = tf.strings.unicode_encode(tf.expand_dims(tokens, -1), \"UTF-8\")\n",
        "bigrams = tf_text.ngrams(characters, 2, reduction_type=tf_text.Reduction.STRING_JOIN, string_separator='')\n",
        "print(bigrams.to_list())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "R8rWv3rAv_cb",
        "outputId": "b7f64280-b5cc-4fe2-bbec-d492ff6c341f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[b'\\xe6\\x96\\xb0\\xe5\\x8d\\x8e\\xe7\\xa4\\xbe', b'\\xe5\\x8c\\x97\\xe4\\xba\\xac']]\n"
          ]
        }
      ],
      "source": [
        "MODEL_HANDLE = \"https://tfhub.dev/google/zh_segmentation/1\"\n",
        "segmenter = tf_text.HubModuleTokenizer(MODEL_HANDLE)\n",
        "tokens = segmenter.tokenize([\"新华社北京\"])\n",
        "print(tokens.to_list())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "XeJHbr8XVctR",
        "outputId": "059360a1-b325-49e5-a111-6b5afcd9f77e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['新华社', '北京']]\n"
          ]
        }
      ],
      "source": [
        "def decode_list(x):\n",
        "  if type(x) is list:\n",
        "    return list(map(decode_list, x))\n",
        "  return x.decode(\"UTF-8\")\n",
        "\n",
        "def decode_utf8_tensor(x):\n",
        "  return list(map(decode_list, x.to_list()))\n",
        "\n",
        "print(decode_utf8_tensor(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3c-2iBiuWgjP",
        "outputId": "78a1a224-1f9b-4730-fffd-ace41bc9f36c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['新华社', '北京']]\n"
          ]
        }
      ],
      "source": [
        "strings = [\"新华社北京\"]\n",
        "labels = [[0, 1, 1, 0, 1]]\n",
        "tokenizer = tf_text.SplitMergeTokenizer()\n",
        "tokens = tokenizer.tokenize(strings, labels)\n",
        "print(decode_utf8_tensor(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "JRWtRYMxw3oc",
        "outputId": "9d9191bf-4fd2-403e-ee81-78451d2ed9cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['新华社', '北京']]\n"
          ]
        }
      ],
      "source": [
        "strings = [[\"新华社北京\"]]\n",
        "labels = [[[5.0, -3.2], [0.2, 12.0], [0.0, 11.0], [2.2, -1.0], [-3.0, 3.0]]]\n",
        "tokenizer = tf_text.SplitMergeFromLogitsTokenizer()\n",
        "tokenizer.tokenize(strings, labels)\n",
        "print(decode_utf8_tensor(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Szw0QZ6ecExC",
        "outputId": "a63bb851-8ef2-4206-c70b-fc9aa2aff344",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[b'What', b'you', b'know', b'you', b\"can't\", b'explain,', b'but', b'you', b'feel', b'it.']]\n"
          ]
        }
      ],
      "source": [
        "splitter = tf_text.RegexSplitter(\"\\s\")\n",
        "tokens = splitter.split([\"What you know you can't explain, but you feel it.\"], )\n",
        "print(tokens.to_list())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "UmZ91zl87J7y",
        "outputId": "06b00d1d-eaa1-4fd5-f8e4-f9d46a54f49d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[b'Everything', b'not', b'saved', b'will', b'be', b'lost', b'.']]\n",
            "[[0, 11, 15, 21, 26, 29, 33]]\n",
            "[[10, 14, 20, 25, 28, 33, 34]]\n"
          ]
        }
      ],
      "source": [
        "tokenizer = tf_text.UnicodeScriptTokenizer()\n",
        "(tokens, start_offsets, end_offsets) = tokenizer.tokenize_with_offsets(['Everything not saved will be lost.'])\n",
        "print(tokens.to_list())\n",
        "print(start_offsets.to_list())\n",
        "print(end_offsets.to_list())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "iyThnPPQ0_6Q",
        "outputId": "21ebd8a5-7c23-433c-ab1e-d3f8fc2b1f9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[87, 104, 97, 116, 32, 121, 111, 117, 32, 107, 110, 111, 119, 32, 121, 111, 117, 32, 99, 97, 110, 39, 116, 32, 101, 120, 112, 108, 97, 105, 110, 44, 32, 98, 117, 116, 32, 121, 111, 117, 32, 102, 101, 101, 108, 32, 105, 116, 46]]\n",
            "[b\"What you know you can't explain, but you feel it.\"]\n"
          ]
        }
      ],
      "source": [
        "tokenizer = tf_text.UnicodeCharTokenizer()\n",
        "tokens = tokenizer.tokenize([\"What you know you can't explain, but you feel it.\"])\n",
        "print(tokens.to_list())\n",
        "strings = tokenizer.detokenize(tokens)\n",
        "print(strings.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "YSykDr1d7uxr",
        "outputId": "6293583a-3d9e-43a9-e7f9-ad2e68fbf790",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[b'Never', b'tell', b'me', b'the', b'odds.']]\n",
            "[[b\"It's\", b'a', b'trap!']]\n"
          ]
        }
      ],
      "source": [
        "docs = tf.data.Dataset.from_tensor_slices([['Never tell me the odds.'], [\"It's a trap!\"]])\n",
        "tokenizer = tf_text.WhitespaceTokenizer()\n",
        "tokenized_docs = docs.map(lambda x: tokenizer.tokenize(x))\n",
        "iterator = iter(tokenized_docs)\n",
        "print(next(iterator).to_list())\n",
        "print(next(iterator).to_list())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "tokenizers.ipynb",
      "toc_visible": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}